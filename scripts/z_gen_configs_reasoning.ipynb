{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def load_test_data(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        temp = json.load(f)\n",
    "    data = {}\n",
    "    for samples in temp[\"data\"].values():\n",
    "        for sample in samples:\n",
    "            data[sample[\"id\"]] = sample\n",
    "    return {\n",
    "        \"gen_subgraph_args\": temp[\"pseudo_subgraphs_args\"],\n",
    "        \"retrieved_subgraph_agrs\": temp[\"retrieve_subgraphs_args\"],\n",
    "        \"data\": data,\n",
    "    }\n",
    "\n",
    "\n",
    "def check_valid_path(path, required_samples=490):\n",
    "    with open(path, \"r\") as f:\n",
    "        data = json.load(f)[\"data\"]\n",
    "    valid = True\n",
    "    invalid_list = []\n",
    "    for samples in data.values():\n",
    "        s = sum([1 for sample in samples if \"retrieved_triplets\" in sample])\n",
    "        if s < required_samples:\n",
    "            valid = False\n",
    "        invalid_list.append(s)\n",
    "    if not valid:\n",
    "        print(f\"Invalid path: {path}\")\n",
    "        print(f\"Invalid samples: {invalid_list}\")\n",
    "    return valid\n",
    "\n",
    "def get_pd_report(retrieved_paths):\n",
    "    pd_data = []\n",
    "    for path in retrieved_paths:\n",
    "        try:\n",
    "            temp = load_test_data(path)\n",
    "            retrieved_subgraph_agrs = temp[\"retrieved_subgraph_agrs\"]\n",
    "            gen_subgraph_args = temp[\"gen_subgraph_args\"]\n",
    "\n",
    "            k_unknown_relations = retrieved_subgraph_agrs[\"algorithm_top_k_unknown_relations\"]\n",
    "            k_unknown_each_connected_node = retrieved_subgraph_agrs[\n",
    "                \"algorithm_top_k_unknown_each_connected_node\"\n",
    "            ]\n",
    "            k_complete_relations = retrieved_subgraph_agrs[\"algorithm_top_k_complete_relations\"]\n",
    "            scoring_method = retrieved_subgraph_agrs[\"scoring_method\"]\n",
    "            llm_size = None\n",
    "            for size in [\"llm_8b\", \"llm_7b\", \"llm_3b\", \"llm_1.5b\", \"llm_1b\"]:\n",
    "                if size in gen_subgraph_args[\"specialized_model_path\"]:\n",
    "                    llm_size = size.split(\"_\")[1]\n",
    "                    break\n",
    "            \n",
    "            num_samples = None\n",
    "            for size in [\"10000\", \"5000\", \"2000\", \"500\", \"100\"]:\n",
    "                if size in gen_subgraph_args[\"specialized_model_path\"]:\n",
    "                    num_samples = int(size)\n",
    "                    break\n",
    "            \n",
    "            num_beams = None\n",
    "            for size in [\"beams_10\", \"beams_5\", \"beams_3\", \"beams_1\"]:\n",
    "                if size in retrieved_subgraph_agrs[\"input_file_path\"]:\n",
    "                    num_beams = int(size.split(\"_\")[1])\n",
    "                    break\n",
    "                \n",
    "            constraint = True\n",
    "            if \"without_constraint\" in retrieved_subgraph_agrs[\"input_file_path\"]:\n",
    "                constraint = False\n",
    "\n",
    "            valid = check_valid_path(path)\n",
    "            pd_data.append(\n",
    "                {\n",
    "                    \"llm\": llm_size,\n",
    "                    \"training\": num_samples,\n",
    "                    \"beams\": num_beams,\n",
    "                    \"constraint\": constraint,\n",
    "                    \"unknown_relations\": k_unknown_relations,\n",
    "                    \"unknown_each_connected_node\": k_unknown_each_connected_node,\n",
    "                    \"complete_relations\": k_complete_relations,\n",
    "                    \"scoring_method\": scoring_method,\n",
    "                    \"valid\": valid,\n",
    "                    \"path\": path,\n",
    "                }\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error in {path}: {e}\")\n",
    "    return pd.DataFrame(pd_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in /home/namb/hoangpv4/kg_fact_checking/data/output/retrieved_subgraphs_dev/specialized_llm_3b_base_5000_checkpoint-157_num_beams_3_retrieved.json: 'pseudo_subgraphs_args'\n",
      "Error in /home/namb/hoangpv4/kg_fact_checking/data/output/retrieved_subgraphs_dev/specialized_llm_3b_base_2000_checkpoint-125_num_beams_3_retrieved.json: 'pseudo_subgraphs_args'\n",
      "Error in /home/namb/hoangpv4/kg_fact_checking/data/output/retrieved_subgraphs_dev/specialized_llm_3b_base_5000_checkpoint-157_num_beams_5_retrieved.json: 'pseudo_subgraphs_args'\n",
      "Error in /home/namb/hoangpv4/kg_fact_checking/data/output/retrieved_subgraphs_dev/specialized_llm_3b_base_2000_checkpoint-125_num_beams_5_retrieved.json: 'pseudo_subgraphs_args'\n",
      "Error in /home/namb/hoangpv4/kg_fact_checking/data/output/retrieved_subgraphs_dev/specialized_llm_3b_base_2000_checkpoint-125_num_beams_1_retrieved.json: 'pseudo_subgraphs_args'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in /home/namb/hoangpv4/kg_fact_checking/data/output/retrieved_subgraphs_dev/specialized_llm_3b_base_5000_checkpoint-157_num_beams_1_retrieved.json: 'pseudo_subgraphs_args'\n",
      "Invalid path: /home/namb/hoangpv4/kg_fact_checking/data/output/retrieved_subgraphs_dev/specialized_llm_8b_base_5000_checkpoint-313/specialized_llm_8b_base_5000_checkpoint-313_num_beams_5_retrieved_-4254586098498722734.json\n",
      "Invalid samples: [500, 500, 500, 500, 160]\n",
      "Invalid path: /home/namb/hoangpv4/kg_fact_checking/data/output/retrieved_subgraphs_dev/specialized_llm_8b_base_5000_checkpoint-313/specialized_llm_8b_base_5000_checkpoint-313_num_beams_5_retrieved_-532697754939918850.json\n",
      "Invalid samples: [500, 500, 500, 500, 160]\n",
      "Invalid path: /home/namb/hoangpv4/kg_fact_checking/data/output/retrieved_subgraphs_dev/specialized_llm_1b_base_5000_checkpoint-157/specialized_llm_1b_base_5000_checkpoint-157_num_beams_10_retrieved_2382825554631171604.json\n",
      "Invalid samples: [500, 500, 500, 500, 425]\n",
      "\n",
      "Found 5 paths\n",
      "/home/namb/hoangpv4/kg_fact_checking/data/output/retrieved_subgraphs_dev/specialized_llm_3b_base_500_checkpoint-125/specialized_llm_3b_base_500_checkpoint-125_num_beams_5_retrieved_embedding_7736124809314354886.json\n",
      "/home/namb/hoangpv4/kg_fact_checking/data/output/retrieved_subgraphs_dev/specialized_llm_3b_base_2000_checkpoint-125/specialized_llm_3b_base_2000_checkpoint-125_num_beams_5_retrieved_5830945564406735299.json\n",
      "/home/namb/hoangpv4/kg_fact_checking/data/output/retrieved_subgraphs_dev/specialized_llm_3b_base_5000_checkpoint-157/specialized_llm_3b_base_5000_checkpoint-157_num_beams_5_retrieved_-3500189888326455151.json\n",
      "/home/namb/hoangpv4/kg_fact_checking/data/output/retrieved_subgraphs_dev/specialized_llm_3b_base_100_checkpoint-100/specialized_llm_3b_base_100_checkpoint-100_num_beams_5_retrieved_embedding_8996180572780529602.json\n",
      "/home/namb/hoangpv4/kg_fact_checking/data/output/retrieved_subgraphs_dev/specialized_llm_3b_base_10000_checkpoint-313/specialized_llm_3b_base_10000_checkpoint-313_num_beams_5_retrieved_embedding_1699614741285503672.json\n"
     ]
    }
   ],
   "source": [
    "retrieved_paths = glob(\n",
    "    \"/home/namb/hoangpv4/kg_fact_checking/data/output/retrieved_subgraphs_dev/**/*.json\",\n",
    "    recursive=True,\n",
    ")\n",
    "pd_data = get_pd_report(retrieved_paths)\n",
    "\n",
    "llm = \"3b\"\n",
    "training = 5000\n",
    "beams = 5\n",
    "constraint = True\n",
    "unknown_relations = 3\n",
    "unknown_each_connected_node = 3\n",
    "complete_relations = 1\n",
    "scoring_method = \"embedding\"\n",
    "valid = True\n",
    "\n",
    "filtered_setup_paths = pd_data[\n",
    "    True\n",
    "    & (pd_data[\"llm\"] == llm)\n",
    "    # & (pd_data[\"training\"] == training)\n",
    "    & (pd_data[\"beams\"] == beams)\n",
    "    & (pd_data[\"constraint\"] == constraint)\n",
    "    & (pd_data[\"unknown_relations\"] == unknown_relations)\n",
    "    & (pd_data[\"unknown_each_connected_node\"] == unknown_each_connected_node)\n",
    "    & (pd_data[\"complete_relations\"] == complete_relations)\n",
    "    & (pd_data[\"scoring_method\"] == scoring_method)\n",
    "    & (pd_data[\"valid\"] == valid)\n",
    "][\"path\"].tolist()\n",
    "\n",
    "print()\n",
    "print(f\"Found {len(filtered_setup_paths)} paths\")\n",
    "for path in filtered_setup_paths:\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCRIPT = \"\"\"\n",
    "export PYTHONPATH=\"$(pwd)\":$PYTHONPATH\n",
    "python workflow/pipeline/llm_reasoning.py \\\n",
    "    --input-file-path {{input_file_path}} \\\n",
    "    --output-folder /home/namb/hoangpv4/kg_fact_checking/data/output/reasoning_results_dev_different_retrieval_params \\\n",
    "    --num-workers 100 \\\n",
    "    --vllm-server-host http://localhost:8264 \\\n",
    "    --model-name Llama-3.3-70B-Instruct \\\n",
    "\"\"\".strip()\n",
    "\n",
    "script_list = []\n",
    "for path in filtered_setup_paths:\n",
    "    script_list.append(\n",
    "        SCRIPT.replace(\"{{input_file_path}}\", path)\n",
    "    )\n",
    "with open(\n",
    "    \"/home/namb/hoangpv4/kg_fact_checking/scripts/reasoning/reasoning_dev_different_retrieval_params.sh\",\n",
    "    \"w\",\n",
    ") as f:\n",
    "    f.write(\"\\n\\n\".join(script_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"\"\"\n",
    "# /home/namb/hoangpv4/kg_fact_checking/data/output/retrieved_subgraphs/specialized_llm_3b_base_5000_checkpoint-157/specialized_llm_3b_base_5000_checkpoint-157_num_beams_5_retrieved_1631798178181607376.json\n",
    "# \"\"\".strip()\n",
    "# with open(path, \"r\") as f:\n",
    "#     temp = json.load(f)\n",
    "# temp.keys()\n",
    "# VERIFY_PROMPT = \"\"\"\n",
    "# ### Task:\n",
    "# Verify whether the fact in the given sentence is true or false based on the provided graph triplets. Use only the information in the triplets for verification.\n",
    "\n",
    "# - The triplets provided represent all relevant knowledge that can be retrieved.\n",
    "# - If the fact is a negation and the triplets do not include the fact, consider the fact as true.\n",
    "# - Ignore questions and verify only the factual assertion within them. For example, in the question 'When was Daniel Martínez (politician) a leader of Montevideo?', focus on verifying the assertion 'Daniel Martínez (politician) a leader of Montevideo'.\n",
    "# - Interpret the \"~\" symbol in triplets as indicating a reverse relationship. For example:\n",
    "#   - \"A ~loves B\" means \"B loves A\".\n",
    "#   - \"A ~south of B\" means \"B is north of A\".\n",
    "# - The unit is not important. (e.g. \"98400\" is also same as 98.4kg)\n",
    "\n",
    "# ### Response Format:\n",
    "# Provide your response in the following JSON format without any additional explanations:\n",
    "# {\n",
    "#     \"rationale\": \"A concise explanation for your decision\",\n",
    "#     \"verdict\": \"true/false as the JSON value\"\n",
    "# }\n",
    "\n",
    "# ### Triplets:\n",
    "# {{triplets}}\n",
    "\n",
    "# ### Claim:\n",
    "# {{claim}}\n",
    "# \"\"\".strip()\n",
    "\n",
    "# from src.utils.batch_utils import BatchUtils\n",
    "# data_dict = {}\n",
    "# for samples in data.values():\n",
    "#     for sample in samples:\n",
    "#         data_dict[sample[\"id\"]] = sample\n",
    "# data_batch = [\n",
    "#     {\n",
    "#         \"id\": key,\n",
    "#         \"messages\": [\n",
    "#             {\n",
    "#                 \"role\": \"system\",\n",
    "#                 \"content\": COT_PROMPT_LLAMA3_70B.replace(\"{{claim}}\", sample[\"claim\"]),\n",
    "#             }\n",
    "#         ],\n",
    "#     }\n",
    "#     for key, sample in data_dict.items()\n",
    "# ]\n",
    "# BatchUtils.prepare_jsonl_for_batch_completions(\n",
    "#     messages_with_ids=data_batch,\n",
    "#     file_name=\"batch_openai_gpt4o_mini_factkg_test_cot.jsonl\",\n",
    "#     output_folder=\"/home/namb/hoangpv4/kg_fact_checking/data/batch_openai\",\n",
    "#     model=\"gpt-4o-mini\",\n",
    "#     temperature=0.0,\n",
    "#     top_p=0.5,\n",
    "#     max_tokens=256,\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
